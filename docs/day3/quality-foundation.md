# Day 3: Welcome & Quality Foundation

## Overview

This opening session transitions from Day 2's "when systems break" to Day 3's "when systems work but data doesn't meet standards." Through discussion and concept introduction, learners explore what quality means in operational contexts and why data quality is a different type of operational challenge requiring similar systematic approaches.

---

## Session Structure

### Discussion: What Does "Good Data" Mean?

#### Opening Frame

**Facilitator Introduction:**

- "Yesterday we focused on incident response - when technical systems break"
- "Today we're exploring a different operational challenge: when systems work fine, but the data doesn't meet our standards"
- "This is about quality and governance - making sure data is 'good enough' for its intended use"

#### Individual Reflection

**Question for learners:**
*"Think about data you use in your work - what makes data 'good' versus 'bad'? What frustrates you most about poor quality data?"*

**Reflection prompts:**

- Think of a time when you couldn't trust data you were given
- What made you lose confidence in a report or dashboard?
- When have you had to spend time cleaning or fixing data before you could use it?

#### Group Sharing

**Structured sharing:**

Each learner shares **one example** (30-45 seconds):

- "Bad data for me is when..."
- "I lose confidence in data when..."
- "The most frustrating data quality issue I face is..."

**Facilitator role:**

- **Listen for patterns** and capture themes on screen/flip chart
- **Group similar responses:** accuracy issues, completeness problems, timeliness concerns
- **Note the business impact** - not just technical problems but work impact

#### Pattern Recognition

**Facilitator synthesis:**

- "I'm hearing themes around accuracy, completeness, timing..."
- "Notice how quality problems affect your ability to do your job"
- "These aren't just technical issues - they have real business consequences"

**Expected themes to emerge:**

- **Accuracy:** Wrong numbers, outdated information
- **Completeness:** Missing records, partial data
- **Consistency:** Same thing measured differently across systems
- **Timeliness:** Data arriving too late to be useful
- **Relevance:** Right data but not quite what's needed
- **Trust:** Uncertainty about whether data can be relied upon

---

### Acquisition: Data Quality as Operational Challenge (8 minutes)

#### Reframe Quality as Operations (3 minutes):

**Connect to Yesterday:**

- "Yesterday you handled incidents - systems failing completely"
- "Today's challenge is more subtle: systems work, but output isn't meeting standards"
- "This requires the same systematic thinking, but different detection and response approaches"

**Quality vs. Incidents:**

```none
SYSTEM INCIDENTS          vs.    DATA QUALITY ISSUES
↓                                ↓
Pipeline stops working           Pipeline produces unreliable data
Clear failure signal           Subtle degradation signal
Immediate impact               Gradual impact
Technical fix needed           Process/standards fix needed
```

#### Why Quality Matters Operationally (3 minutes):

**Business Impact Examples:**

- **Decision-making:** Executives making strategic decisions based on inaccurate data
- **Customer experience:** Personalization systems using outdated customer preferences
- **Compliance:** Regulatory reports with incomplete or inconsistent data
- **Efficiency:** Teams spending time validating data instead of analyzing it

**The Quality Challenge:**

- **Detection is harder:** Systems appear to be working fine
- **Standards are subjective:** "Good enough" varies by use case
- **Prevention requires governance:** Processes, policies, and culture change
- **Impact is often delayed:** Problems discovered weeks or months later

#### Operational Quality Dimensions

**Quick introduction to key concepts:**

- **Fitness for purpose:** Data quality depends on how it will be used
- **Quality standards:** Need clear, measurable criteria
- **Quality monitoring:** Ongoing measurement, not one-time assessment
- **Quality improvement:** Systematic processes for addressing issues

**Preview today's approach:**

- "We'll define quality standards using proven frameworks"
- "See how to implement quality patterns in data architectures"
- "Practice balancing quality requirements with practical constraints"

---

## Transition to Next Session

### Bridge to DMBOK Investigation

**Facilitator:**

- "You've identified quality challenges from your experience"
- "Now we'll explore a professional framework for thinking about data quality"
- "The DMBOK (Data Management Body of Knowledge) provides six specific dimensions for measuring and improving data quality"
- "This will give you systematic language for the quality issues you've experienced"

---

## Resources for Trainers

### Managing the Discussion

**If learners struggle to think of examples:**

- "Think about spreadsheets you've received that had problems"
- "Consider dashboards or reports where you questioned the numbers"
- "What about customer data that seemed outdated or wrong?"

**If examples get too technical:**

- "Focus on the impact on your work, not the technical cause"
- "How did the quality problem affect your decision-making?"

**If discussion goes long:**

- **Capture themes quickly** and move to acquisition
- "I'm hearing great examples - let's put framework around these experiences"

### Common Quality Issues to Expect:

**Accuracy Problems:**

- Wrong customer contact information
- Incorrect financial calculations
- Outdated product pricing

**Completeness Issues:**

- Missing customer records
- Partial transaction data
- Incomplete survey responses

**Consistency Problems:**

- Different systems showing different customer names
- Conflicting sales figures across reports
- Varying date formats

**Timeliness Issues:**

- Reports showing yesterday's data for real-time decisions
- Batch processing delays affecting morning meetings
- Historical data needed but not available

### Key Insights to Highlight:

**Quality is Contextual:**

- Data that's "good enough" for one purpose may be inadequate for another
- Quality requirements change based on business criticality
- Perfect data quality is often neither necessary nor cost-effective

**Quality is Operational:**

- Requires ongoing monitoring, not just initial assessment
- Needs clear standards and measurement processes
- Benefits from the same systematic thinking as incident response

**Quality is Organizational:**

- Often involves multiple teams and systems
- Requires governance processes and clear accountability
- Culture and processes matter as much as technology

### Expected Outcomes:

By the end of this session, learners should:

1. **Connect personal experience** with formal data quality concepts
2. **Understand quality as operational challenge** requiring systematic approaches
3. **Appreciate the business impact** of data quality issues
4. **Be prepared to explore** structured frameworks for defining and measuring quality

### Connection to KSBs:

- **K4:** Frameworks for data quality covering dimensions such as accuracy, completeness, consistency
- **S26:** Identify data quality metrics and track them to ensure quality, accuracy and reliability
- **K5:** The inherent risks of data such as incomplete data, ethical data sources
- **B3:** Quality focus that promotes continuous improvement
