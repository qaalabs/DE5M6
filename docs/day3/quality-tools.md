# Quality Tools Investigation

## Tool Categories to Research

### Group A: Data Quality Frameworks

- **Great Expectations:** Python-based data validation framework
- **dbt tests:** Built-in and custom data quality tests

❓ How do these tools implement quality checks?

---

### Group B: Cloud-Native Quality Tools

- **Azure Data Quality (in Fabric/Synapse):** Built-in quality monitoring
- **AWS Glue DataBrew:** Visual data quality profiling

❓ How do cloud platforms handle quality monitoring and alerting?

---

### Group C: Quality Monitoring & Observability

- **Monte Carlo:** Data observability and quality monitoring
- **Datadog Data Streams:** Real-time quality monitoring

❓ How do these tools detect quality issues automatically?

---

### Group D: Open Source Quality Solutions

- **Apache Griffin:** Data quality platform
- **DataHub:** Data discovery with quality insights

❓ How do open source tools provide cost-effective quality solutions?

---

## Research Guidelines

**For each tool category, investigate:**

### Implementation Approach

- How would this tool integrate with a medallion architecture?
- What quality checks could be automated?
- How does it compare to manual validation?

### Quality Dimensions Covered

- Which DMBOK dimensions does this tool address best?
- What types of quality issues would it catch/miss?
- How does it handle quality monitoring vs. quality improvement?

### Practical Considerations

- What skills/resources needed for implementation?
- How does it fit with Microsoft Fabric/Azure ecosystem?
- What would be the first quality check you'd implement?

---

## Teach Back

- Each group presents what they have found.
